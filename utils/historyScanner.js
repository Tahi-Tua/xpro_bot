const fs = require("fs");
const fsPromises = require("fs").promises;
const path = require("path");
const { EmbedBuilder } = require("discord.js");
const { MODERATION_LOG_CHANNEL_ID, MOD_ROLE_NAME, FILTER_EXEMPT_CHANNEL_IDS } = require("../config/channels");
const { containsBadWord, findBadWords } = require("../handlers/badwords");
const { detectSpamViolations } = require("../handlers/spam");
const { hasBypassRole } = require("../utils/bypass");

const scanStateFile = path.join(__dirname, "../data/scanState.json");

const FILTER_EXEMPT_SET = new Set(FILTER_EXEMPT_CHANNEL_IDS || []);

// A simple promise-based queue to serialize updates to the scan state file.
// Without this, concurrent scans may overwrite each other's progress.  Each
// call to `updateScanState` is enqueued and executed sequentially.
let scanStateQueue = Promise.resolve();

// In-memory cache of the scan state to avoid stale reads from disk.
// This is updated atomically within the queue to ensure consistency.
let cachedScanState = null;

/**
 * Update the saved scan state for a specific channel.  This helper
 * serializes updates to avoid race conditions where concurrent scans
 * overwrite each other's progress.  It maintains an in-memory cache
 * that is updated atomically and persisted to disk.
 *
 * @param {string} channelId The ID of the channel that was scanned.
 * @param {string} newestMessageId The ID of the newest message that was scanned.
 * @returns {Promise<void>} A promise that resolves once the update is complete.
 */
function updateScanState(channelId, newestMessageId) {
  scanStateQueue = scanStateQueue
    .then(async () => {
      // Load from cache or disk on first access
      if (cachedScanState === null) {
        cachedScanState = loadScanState();
      }
      
      // Update the cached state atomically
      cachedScanState[channelId] = newestMessageId;
      
      // Persist to disk asynchronously
      await saveScanState(cachedScanState);
    })
    .catch((err) => {
      console.error("Failed to update scan state:", err.message);
      // Invalidate cache on error to force reload on next update
      cachedScanState = null;
    });
  return scanStateQueue;
}

function loadScanState() {
  try {
    const data = fs.readFileSync(scanStateFile, "utf8");
    return JSON.parse(data);
  } catch {
    return {};
  }
}

/**
 * Save scan state to disk asynchronously to prevent event loop blocking.
 * This is called within the queue so it's already serialized.
 */
async function saveScanState(state) {
  try {
    await fsPromises.writeFile(scanStateFile, JSON.stringify(state, null, 2), "utf8");
  } catch (err) {
    console.error("Failed to write scan state:", err.message);
    throw err; // Re-throw to trigger cache invalidation in updateScanState
  }
}

function detectSpamPatterns(message) {
  return detectSpamViolations(message) || [];
}

async function sendViolationDM(user, violations) {
  try {
    const embed = new EmbedBuilder()
      .setColor(0xff6b6b)
      .setTitle("âš ï¸ Message Violation Notice")
      .setDescription("Your message was found to violate server rules during a history scan.")
      .addFields(
        { name: "Violations", value: violations.join("\n") || "Unknown" },
        { name: "Action", value: "Your message has been deleted" },
        { name: "Note", value: "Please review the server rules and avoid this behavior in the future." }
      )
      .setTimestamp();

    await user.send({ embeds: [embed] }).catch(() => {});
  } catch (err) {
    console.error(`Failed to send DM to ${user.tag}:`, err.message);
  }
}

async function sendMemberScanReport(guild, user, violations) {
  try {
    const totalViolations = violations.length;
    
    // Count violation types
    let badWordCount = 0;
    let spamCount = 0;
    const typeBreakdown = {};
    
    violations.forEach(v => {
      if (v.type.includes("Bad Words")) {
        badWordCount++;
      } else if (v.type.includes("Insult")) {
        if (!typeBreakdown["Insults"]) typeBreakdown["Insults"] = 0;
        typeBreakdown["Insults"]++;
      } else {
        spamCount++;
        if (!typeBreakdown[v.type]) typeBreakdown[v.type] = 0;
        typeBreakdown[v.type]++;
      }
    });
    
    const report = new EmbedBuilder()
      .setColor(0xff6b6b)
      .setTitle("ðŸ“‹ Your Violation Report")
      .setDescription("Report Type: **ðŸ”µ History Scan**\nStatus: **ACTIVE MONITORING**")
      .setThumbnail(user.displayAvatarURL({ dynamic: true, size: 256 }))
      .addFields(
        { 
          name: "ðŸ‘¤ Member", 
          value: `${user}`, 
          inline: true 
        },
        { 
          name: "ðŸ”¢ Total Violations", 
          value: `**${totalViolations}**`, 
          inline: true 
        },
        { 
          name: "ðŸ“… Scan Date", 
          value: new Date().toLocaleDateString(), 
          inline: true 
        }
      );

    // Add violation breakdown
    if (badWordCount > 0) {
      report.addFields({
        name: "ðŸ”´ Bad Words/Insults",
        value: `**${badWordCount}** violation${badWordCount !== 1 ? 's' : ''}`,
        inline: true
      });
    }
    if (spamCount > 0) {
      report.addFields({
        name: "ðŸŸ  Spam Violations",
        value: `**${spamCount}** violation${spamCount !== 1 ? 's' : ''}`,
        inline: true
      });
    }

    // Add detailed type breakdown
    if (Object.keys(typeBreakdown).length > 0) {
      const breakdownText = Object.entries(typeBreakdown)
        .map(([type, count]) => `â€¢ ${type}: **${count}**`)
        .join("\n");
      
      report.addFields({
        name: "ðŸ“Š Type Breakdown",
        value: breakdownText,
        inline: false
      });
    }

    if (violations.length > 0) {
      const violationsList = violations
        .slice(0, 8)
        .map((v, i) => `**${i + 1}.** ${v.type}\nâ””â”€ *${v.content.substring(0, 70)}${v.content.length > 70 ? '...' : ''}*`)
        .join("\n\n");
      
      report.addFields({
        name: "ðŸš¨ Recent Violations",
        value: violationsList,
        inline: false
      });
    }

    report.addFields({
      name: "âš ï¸ Warning",
      value: "This report is **actively being monitored**. Each future violation will be tracked and added to your record.",
      inline: false
    });

    report
      .setFooter({ text: "Automated Moderation System â€¢ History Scan Report" })
      .setTimestamp();

    await user.send({ embeds: [report] }).catch(() => {});
  } catch (err) {
    console.error(`Failed to send report to ${user.tag}:`, err.message);
  }
}

async function scanChannel(channel, options = {}) {
  const { maxMessages = 500, deleteViolations = false, logChannel = null, guild = null } = options;

  if (FILTER_EXEMPT_SET.has(channel.id)) {
    return {
      scanned: 0,
      badwords: [],
      spam: [],
      errors: [],
    };
  }
  
  const state = loadScanState();
  const lastScannedId = state[channel.id];
  
  const results = {
    scanned: 0,
    badwords: [],
    spam: [],
    errors: [],
  };

  let lastMessageId = null;
  let messagesProcessed = 0;
  let reachedLastScanned = false;
  const memberViolations = new Map(); // Store violations per member

  try {
    fetchLoop: while (messagesProcessed < maxMessages) {
      const fetchOptions = { limit: 100 };
      if (lastMessageId) {
        fetchOptions.before = lastMessageId;
      }

      const messages = await channel.messages.fetch(fetchOptions);
      if (messages.size === 0) break;

      for (const [id, message] of messages) {
        if (lastScannedId && BigInt(id) <= BigInt(lastScannedId)) {
          reachedLastScanned = true;
          break;
        }

        if (message.author.bot) continue;
        if (hasBypassRole(message.member)) continue;

        messagesProcessed++;
        results.scanned++;

        const content = message.content || "";
        let hasViolation = false;
        const violations = [];

        if (containsBadWord(content)) {
          const matchedWords = findBadWords(content);
          results.badwords.push({
            id: message.id,
            author: message.author.tag,
            authorId: message.author.id,
            content: content.slice(0, 200),
            words: matchedWords,
            url: message.url,
          });
          violations.push({
            type: "ðŸ”´ Bad Words",
            words: matchedWords,
            content: content.slice(0, 100)
          });
          hasViolation = true;

          if (deleteViolations) {
            await message.delete().catch(() => {});
          }
        }

        const spamIssues = detectSpamPatterns(message);
        if (spamIssues.length > 0) {
          results.spam.push({
            id: message.id,
            author: message.author.tag,
            authorId: message.author.id,
            content: content.slice(0, 200),
            issues: spamIssues,
            url: message.url,
          });
          
          spamIssues.forEach(issue => {
            violations.push({
              type: `ðŸŸ  ${issue}`,
              content: content.slice(0, 100)
            });
          });
          hasViolation = true;

          if (deleteViolations) {
            await message.delete().catch(() => {});
          }
        }

        // Store violations per member
        if (hasViolation) {
          if (!memberViolations.has(message.author.id)) {
            memberViolations.set(message.author.id, {
              author: message.author,
              violations: []
            });
          }
          memberViolations.get(message.author.id).violations.push(...violations);
        }

        if (messagesProcessed >= maxMessages) break;
      }

      lastMessageId = messages.last()?.id;
      if (!lastMessageId || reachedLastScanned) break fetchLoop;

      await new Promise((resolve) => setTimeout(resolve, 1000));
    }

    // Send individual reports to members with violations
    for (const [memberId, data] of memberViolations.entries()) {
      await sendMemberScanReport(guild, data.author, data.violations);
      await new Promise((resolve) => setTimeout(resolve, 500)); // Rate limit DMs
    }

    const newestMessageId = (await channel.messages.fetch({ limit: 1 })).first()?.id;
    if (newestMessageId) {
      // Use the queued update function to prevent concurrent writes clobbering each other
      await updateScanState(channel.id, newestMessageId);
    }

  } catch (err) {
    results.errors.push(err.message);
  }

  return results;
}

async function logScanResults(guild, channel, results) {
  const logChannel = guild.channels.cache.get(MODERATION_LOG_CHANNEL_ID);
  if (!logChannel) return;

  const totalViolations = results.badwords.length + results.spam.length;
  const violationRate = results.scanned > 0 ? ((totalViolations / results.scanned) * 100).toFixed(2) : 0;

  // Main embed with statistics
  const mainEmbed = new EmbedBuilder()
    .setColor(totalViolations > 0 ? 0xff6b6b : 0x2ecc71)
    .setTitle("ðŸ” HISTORY SCAN RESULTS")
    .setThumbnail(guild.iconURL({ dynamic: true }))
    .addFields(
      { 
        name: "ðŸ“ Channel Scanned", 
        value: `${channel}`, 
        inline: true 
      },
      { 
        name: "ðŸ“Š Messages Analyzed", 
        value: `**${results.scanned}**`, 
        inline: true 
      },
      { 
        name: "ðŸ“ˆ Violation Rate", 
        value: `**${violationRate}%**`, 
        inline: true 
      }
    )
    .addFields(
      { 
        name: "ðŸš¨ Total Violations Found", 
        value: `**${totalViolations}**`, 
        inline: false 
      }
    );

  // Statistics rows
  const statsValue = 
    `\`\`\`
ðŸ”´ Bad Words:     ${results.badwords.length}
ðŸŸ  Spam Issues:   ${results.spam.length}
\`\`\``;
  mainEmbed.addFields({
    name: "ðŸ“‹ Violation Breakdown",
    value: statsValue,
    inline: false
  });

  // Bad words violations with details
  if (results.badwords.length > 0) {
    const badwordDetails = results.badwords
      .slice(0, 8)
      .map((v, i) => {
        const snippet = v.content.replace(/\n/g, " ");
        return `**${i + 1}. ${v.author}**\nâ””â”€ *"${snippet.substring(0, 80)}${snippet.length > 80 ? '...' : ''}"*`;
      })
      .join("\n\n");
    
    mainEmbed.addFields({
      name: `ðŸ”´ Bad Words Violations (${results.badwords.length} total)`,
      value: badwordDetails || "None",
      inline: false
    });
  }

  // Spam violations with details
  if (results.spam.length > 0) {
    const spamDetails = results.spam
      .slice(0, 8)
      .map((v, i) => {
        const snippet = v.content.replace(/\n/g, " ");
        const issues = v.issues.map(issue => `\`${issue}\``).join(", ");
        return `**${i + 1}. ${v.author}**\nâ””â”€ ${issues}\nâ””â”€ *"${snippet.substring(0, 70)}${snippet.length > 70 ? '...' : ''}"*`;
      })
      .join("\n\n");
    
    mainEmbed.addFields({
      name: `ðŸŸ  Spam Violations (${results.spam.length} total)`,
      value: spamDetails || "None",
      inline: false
    });
  }

  // Summary footer
  const summaryText = totalViolations === 0 
    ? "âœ… No violations found! Channel is clean." 
    : `âš ï¸ ${totalViolations} violation${totalViolations !== 1 ? 's' : ''} detected and processed.`;
  
  mainEmbed.addFields({
    name: "ðŸ“Œ Summary",
    value: summaryText,
    inline: false
  });

  if (results.errors.length > 0) {
    mainEmbed.addFields({
      name: "âš ï¸ Errors During Scan",
      value: results.errors.join("\n").slice(0, 500),
      inline: false
    });
  }

  mainEmbed
    .setFooter({ text: "Automated Security Scan" })
    .setTimestamp();

  const staffRole = guild.roles.cache.find((r) => r.name === MOD_ROLE_NAME);
  await logChannel.send({
    content: staffRole && totalViolations > 0 ? `${staffRole}` : "",
    embeds: [mainEmbed],
  }).catch(() => {});
}

module.exports = {
  scanChannel,
  logScanResults,
  containsBadWord,
  detectSpamPatterns,
  sendViolationDM,
  sendMemberScanReport,
};
